{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZsi2xz76pwh"
      },
      "source": [
        "## Attrition:- ***company losing its customer base***\n",
        "\n",
        "**Attrition is a process in which the workforce dwindles at a company, following a period in which a number of people retire or resign, and are not replaced.**\n",
        "- A reduction in staff due to attrition is often called a hiring freeze and is seen as a less disruptive way to trim the workforce and reduce payroll than layoffs\n",
        "- In this NoteBook our Aim will be to analyze the datasets completely wrt each and feature and find the reasin behind Attrition of Employees.\n",
        "- And what the top factors which lead to employee attrition?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTJFLhlN6pwr"
      },
      "source": [
        "### Description about the data\n",
        "\n",
        "- Age: A period of employee life, measured by years from birth.\n",
        "- Attrition: The departure of employees from the organization.\n",
        "- BusinessTravel: Did the employee travel on a business trip or not.\n",
        "- DailyRate: Employee salary for the period is divided by the amount of calendar days in the period.\n",
        "- Department: In which department the Employee working.\n",
        "- DistanceFromHome: How far the Employee live from the office location.\n",
        "- Education: In education 1 means 'Below College', 2 means 'College', 3 means 'Bachelor', 4 means 'Master', 5 means 'Doctor'\n",
        "- EducationField: In which field Employee complete his education.\n",
        "- EmployeeCount: How many employee working in a department\n",
        "- EmployeeNumber: An Employee Number is a unique number that has been assigned to each current and former State employee and elected official in the Position and Personnel\n",
        "DataBase (PPDB).\n",
        "- Job involvement: Is the degree to which an employee identifies with their work and actively participates in it where 1 means 'Low', 2 means 'Medium', 3 means 'High', 4 means 'Very High'\n",
        "- JobLevel: Job levels, also known as job grades and classifications, set the responsibility level and expectations of roles at your organization. They may be further defined\n",
        "by impact, seniority, knowledge, skills, or job title, and are often associated with a pay band. The way you structure your job levels should be dictated by the needs of your\n",
        "unique organization and teams.\n",
        "- JobRole: What is the jobrole of an employee.\n",
        "- JobSatisfaction: Employee job satisfaction rate where, 1 means 'Low', 2 means 'Medium', 3 means 'High', 4 means 'Very High'\n",
        "- MaritalStatus: Marital status of the employee.\n",
        "- MonthlyIncome: total monetary value paid by the organization to an employee.\n",
        "- MonthlyRate: The per-day wage of the employee.\n",
        "- NumCompaniesWorked: Before joining this organization how many organizations employee worked.\n",
        "- Over18: Is the employee age over than 18 or not.\n",
        "- OverTime: A Employee works more than 9 hours in any day or for more than 48 hours in any week.\n",
        "- PercentSalaryHike:\n",
        "- PerformanceRating 1 'Low' 2 'Good' 3 'Excellent' 4 'Outstanding'\n",
        "- EnvironmentSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
        "- RelationshipSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
        "- StandardHours: Is the number of hours of production time that should have been used during an working period.\n",
        "- StockOptionLevel:  Employee stock options, also known as ESOs, are stock options in the company’s stock granted by an employer to certain employees. Typically they are  granted to those in management or officer-level positions. Stock options give the employee the right to buy a certain amount of stock at a specific price, during a specific period of time. Options typically have expiration dates as well, by which the options must have been exercised, otherwise they will become worthless.\n",
        "- TotalWorkingYears: Total years the employee working in any organization\n",
        "- TrainingTimesLastYear: Last year how many times employee took training session.\n",
        "- WorkLifeBalance 1 'Bad' 2 'Good' 3 'Better' 4 'Best'\n",
        "- YearsAtCompany: How many years the employee working in the current organization\n",
        "- YearsInCurrentRole: How many years the employee working in the current position\n",
        "- YearsSinceLastPromotion: How many years the employee working in the current position after promotion\n",
        "- YearsWithCurrManager: How many years the employee working under the current manager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qZmvMqC6pwu"
      },
      "source": [
        "<h2>Some Python Libraries</h2>\n",
        "\n",
        "<p style=\"text-align: justify;\">In the first place, Let's define some libraries to help us in the manipulation the data set, such as `pandas`, `numpy`, `matplotlib`, `seaborn`. In this tutorial, we are implementing a Logistic Regression with `sikit-learn`. The goal here is to be as simple as possible! So to help you with this task, we implementing the Logistic regression using ready-made libraries and their functinality.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "4E8q4i4C6pww"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU6cPva16pw0"
      },
      "source": [
        "<h2>Get the Data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true,
        "id": "PwC9X0ut6pw1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "3ed9496a-b699-4a67-cccf-539b57069a49"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Employee-Attrition.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fd778d5bdd9f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Employee-Attrition.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Employee-Attrition.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('Employee-Attrition.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "bTy_a7gtduG_",
        "outputId": "a7de4411-0219-4fde-9ae3-392a59868f94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jqZly9w6pw2"
      },
      "source": [
        "<h2>Basic Data Exploration</h2>\n",
        "\n",
        "- This is an Important Step in Data Science and Machine Learning to ensure about the columns, and rows present.\n",
        "- First, we will check the shape of the dataset\n",
        "- Second, we will check the head, tail, and sample of the datasets\n",
        "- Third, we will check the Data Description\n",
        "- Then, we will check the Data Types of the columns present in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "m7-TmJH96pw4"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMYiKINZ6pw6"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkDdH1u46pw8"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "9GEY277q6pw9"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "K59Gk4hA6pw-"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRoa-G-O6pw_"
      },
      "source": [
        "**Observations**\n",
        "* we only have int and string data types features. there is no feature with float. 26 features are numerical and 9 features are categorical\n",
        "* Attrition in out target value which has no missing value. But, the quantity of data of emp having Attrition is less compared to employees whoch do not have Attrition.\n",
        "- It's very good that we are having a complete dataset, there is no any missing values in dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVv1e3vI6pxF"
      },
      "source": [
        "## Check Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKD7m_8h6pxG"
      },
      "outputs": [],
      "source": [
        "print(data.duplicated().value_counts())\n",
        "data.drop_duplicates(inplace = True)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ysBXEib6pxH"
      },
      "source": [
        "## Checking missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_Ac6dMr6pxM"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn35427P6pxN"
      },
      "source": [
        "## Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O8g7t3k6pxO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.rc(\"font\", size=14)\n",
        "sns.countplot(y ='Attrition',data=data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOWn3-bW6pxP"
      },
      "source": [
        "Over here we noticed that the Target column is Highly Imbalanced, we need to balance the data by using some Statistical Methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVwCgfYh6pxU"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg4zYm566pxV"
      },
      "outputs": [],
      "source": [
        "# Department wrt Attrition\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x='Department',hue='Attrition', data=data, palette='hot')\n",
        "plt.title(\"Attrition w.r.t Department\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_y-SnFb6pxW"
      },
      "outputs": [],
      "source": [
        "# Department wrt Attrition\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x='EducationField',hue='Attrition', data=data, palette='hot')\n",
        "plt.title(\"Attrition w.r.t EducationField\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVRuR-dx6pxW"
      },
      "outputs": [],
      "source": [
        "# let's see at which post most people are leaving the jobs\n",
        "# JobRole\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x='JobRole',hue='Attrition', data=data, palette='hot')\n",
        "plt.title(\"JobRole w.r.t Attrition\")\n",
        "plt.legend(loc='best')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCFu-TFs6pxc"
      },
      "outputs": [],
      "source": [
        "# most male of female employes Attriate\n",
        "# Department wrt Attrition\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x='Gender',hue='Attrition', data=data, palette='hot')\n",
        "plt.title(\"Gender w.r.t Attrition\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD-mCTww6pxe"
      },
      "source": [
        "**OBSERVATIONS**\n",
        "- Employees working in R&D department are more, but employees from sales department or at position like sales executive,sale Representative leaves the job early.\n",
        "- Males are more under Attrition then Females"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QcWjPfR6pxf"
      },
      "outputs": [],
      "source": [
        "# distribution of age\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.distplot(data['Age'],hist=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmbrJLP-6pxl"
      },
      "source": [
        "* Age column is very well normalized, most of employees are age between 25 to 40.\n",
        "- we are having some of the numerical columns which are lebel encoded for us, they are ordinal labels, so let's have a look at them first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xLJZ8Bp6pxl"
      },
      "outputs": [],
      "source": [
        "ordinal_features = ['Education','EnvironmentSatisfaction','JobInvolvement','JobSatisfaction',\n",
        "                    'PerformanceRating','RelationshipSatisfaction','WorkLifeBalance']\n",
        "data[ordinal_features].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dn1uhpu6pxm"
      },
      "outputs": [],
      "source": [
        "edu_map = {1 :'Below College', 2: 'College', 3 :'Bachelor', 4 :'Master', 5: 'Doctor'}\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x=data['Education'].map(edu_map), hue='Attrition', data=data, palette='hot')\n",
        "plt.title(\"Education W.R.T Attrition\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MN7W91P6pxr"
      },
      "source": [
        "**OBSERVATIONS**\n",
        "- Employees from Bachelor are more, then from Masters background. Attrition wrt to bachelor can be seem more because they have more and more expectation from companies and it will be interesting to see the reason behind this in this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADRwwOql6pxs"
      },
      "source": [
        "## Label Encodeing\n",
        "\n",
        "In machine learning, we usually deal with datasets that contain multiple labels in one or more than one columns. These labels can be in the form of words or numbers. To make the data understandable or in human-readable form, the training data is often labelled in words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9TuTxAE6pxs"
      },
      "outputs": [],
      "source": [
        "# Target Variable(Attrition)\n",
        "data['Attrition'] = data['Attrition'].replace({'No':0,'Yes':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHmJU6Oo6pxt"
      },
      "outputs": [],
      "source": [
        "#encode binary variables\n",
        "data['OverTime'] = data['OverTime'].map({'No':0,'Yes':1})\n",
        "data['Gender'] = data['Gender'].map({'Male':0,'Female':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwhtHscF6pxz"
      },
      "outputs": [],
      "source": [
        "# encode categorical columns which are ordinal, use labelEncoding\n",
        "# apply Label encoder to df_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoding_cols=['BusinessTravel','Department','EducationField','JobRole','MaritalStatus']\n",
        "label_encoders = {}\n",
        "for column in encoding_cols:\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "    data[column] = label_encoders[column].fit_transform(data[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JquS-K8G6px0"
      },
      "outputs": [],
      "source": [
        "# look at the final data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg7WFXvR6px1"
      },
      "source": [
        "## Machine Learning: Splitting the data into Training and Testing sample\n",
        "We dont use the full data for creating the model. Some data is randomly selected and kept aside for checking how good the model is. This is known as Testing Data and the remaining data is called Training data on which the model is built. Typically 70% of data is used as Training data and the rest 30% is used as Tesing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "O7z9PE3H6px2"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['Attrition','Over18'], axis=1)\n",
        "y = data['Attrition'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y273xwp6px8"
      },
      "source": [
        "# Resampling\n",
        "Resampling is the method that consists of drawing repeated samples from the original data samples. The method of Resampling is a nonparametric method of statistical inference\n",
        "Oversampling and undersampling in data analysis are techniques used to adjust the class distribution of a data set. These terms are used both in statistical sampling, survey design methodology and in machine learning. Oversampling and undersampling are opposite and roughly equivalent techniques\n",
        "- We are going to use Over Sampling.\n",
        "- We will not use Under Sampling to avoid data loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-SYl2bl6pyV"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "print(Counter(y))\n",
        "rus = RandomOverSampler(random_state = 42)\n",
        "X_over, y_over = rus.fit_resample(X,y)\n",
        "print(Counter(y_over))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pZ6K9xN6pyW"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVVDsNB86pyc"
      },
      "outputs": [],
      "source": [
        "# Sanity check for the sampled data\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDJLrJg26pye"
      },
      "source": [
        "# Logistic Regression in Machine Learning\n",
        "\n",
        "Logistic Regression is used for predicting a category, specially the Binary categories(Yes/No , 0/1).\n",
        "\n",
        "For example, whether to approve a loan or not (Yes/No)? Which group does this customer belong to (Silver/Gold/Platinum)? etc.\n",
        "\n",
        "When there are only two outcomes in Target Variable it is known as Binomial Logistic Regression.\n",
        "\n",
        "If there are more than two outcomes in Target Variable it is known as Multinomial Logistic Regression.\n",
        "\n",
        "If the outcomes in Target Variable are ordinal and there is a natural ordering in the values (eg. Small< Medium< Large) then it is known as Ordinal Logistic Regression.\n",
        "</br>\n",
        "<a href=\"https://ibb.co/k33M6Ys\"><img src=\"https://i.ibb.co/pWWnrCB/image-12.png\" alt=\"image-12\" border=\"0\"></a>\n",
        "</br>\n",
        "Logistic regression is based on logit function logit(x) = log(x / (1 – x))\n",
        "\n",
        "The output is a value between 0 to 1. It is the probability of an event’s occurrence.\n",
        "\n",
        "E.g. There is an 80% chance that the loan application is good, approve it.\n",
        "\n",
        "The coefficients β0, β1, β2, β3… are found using Maximum Likelihood Estimation Technique. Basically, if the Target Variable’s value (y) is 1, then the probability of one “P(1)” should be as close to 1 as possible and the probability of zero “P(0)” should be as close to 0 as possible. Find those coefficients which satisfy both the conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eakZRdmD6pye"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDl-Jj6Z6pyj"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKeD-RlX6pyk"
      },
      "outputs": [],
      "source": [
        "prediction=logreg.predict(X_test)\n",
        "cnf_matrix = confusion_matrix(y_test,prediction)\n",
        "print(\"Accuracy Score -\", accuracy_score(y_test , prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB8Myhg96pyl"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (15,6))\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1 = sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\n",
        "bottom, top = ax1.get_ylim()\n",
        "ax1.set_ylim(bottom + 0.5, top - 0.5)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Expected')\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = roc_curve(y_test,  prediction)\n",
        "auc = roc_auc_score(y_test, prediction)\n",
        "ax2 = plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier"
      ],
      "metadata": {
        "id": "ikuRsk7rhloG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c27i8QL6pyq"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dectree = DecisionTreeClassifier()\n",
        "dectree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Psy9lO2Zf8sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=dectree.predict(X_test)\n",
        "cnf_matrix = confusion_matrix(y_test,prediction)\n",
        "print(\"Accuracy Score -\", accuracy_score(y_test , prediction))"
      ],
      "metadata": {
        "id": "qyXau33HkSle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (15,6))\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1 = sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\n",
        "bottom, top = ax1.get_ylim()\n",
        "ax1.set_ylim(bottom + 0.5, top - 0.5)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Expected')\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "y_pred_proba = dectree.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = roc_curve(y_test,  prediction)\n",
        "auc = roc_auc_score(y_test, prediction)\n",
        "ax2 = plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g03agrVYhgWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "dw8D8MOulRl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "F5fU22IykM4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rc = RandomForestClassifier()\n",
        "rc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "gAC-xL32lx-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=rc.predict(X_test)\n",
        "cnf_matrix = confusion_matrix(y_test,prediction)\n",
        "print(\"Accuracy Score -\", accuracy_score(y_test , prediction))"
      ],
      "metadata": {
        "id": "L-gs5fa0l8Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (15,6))\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1 = sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\n",
        "bottom, top = ax1.get_ylim()\n",
        "ax1.set_ylim(bottom + 0.5, top - 0.5)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Expected')\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "y_pred_proba = rc.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = roc_curve(y_test,  prediction)\n",
        "auc = roc_auc_score(y_test, prediction)\n",
        "ax2 = plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h26bQ0ajmBMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}